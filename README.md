# Parallel-Web-Crawler
Crawling refers to the process of going to a webpage, following all the links from it, following all the links in the found pages, etc. This process is used, for example, by search engines to index the content of the Internet. The goal of this project is to crawl a website to create its “index”, a list of pages.
